{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" Models that use various Approximate Nearest Neighbours libraries in order to quickly\n",
    "generate recommendations and lists of similar items.\n",
    "See http://www.benfrederickson.com/approximate-nearest-neighbours-for-recommender-systems/\n",
    "\"\"\"\n",
    "import time\n",
    "import sys\n",
    "import numpy\n",
    "import itertools\n",
    "try:\n",
    "    import annoy\n",
    "except ImportError:\n",
    "    print(\"The package 'annoy' is required to run this example.\")\n",
    "    sys.exit()\n",
    "\n",
    "try:\n",
    "    import nmslib\n",
    "except ImportError:\n",
    "    print(\"The package 'nmslib' is required to run this example.\")\n",
    "    sys.exit()\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import logging\n",
    "log = logging.getLogger(\"recsys\")\n",
    "\n",
    "\n",
    "\n",
    "def augment_inner_product_matrix(factors):\n",
    "    \"\"\" This function transforms a factor matrix such that an angular nearest neighbours search\n",
    "    will return top related items of the inner product.\n",
    "    This involves transforming each row by adding one extra dimension as suggested in the paper:\n",
    "    \"Speeding Up the Xbox Recommender System Using a Euclidean Transformation for Inner-Product\n",
    "    Spaces\" https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/XboxInnerProduct.pdf\n",
    "    Basically this involves transforming each feature vector so that they have the same norm, which\n",
    "    means the cosine of this transformed vector is proportional to the dot product (if the other\n",
    "    vector in the cosine has a 0 in the extra dimension). \"\"\"\n",
    "    norms = numpy.linalg.norm(factors, axis=1)\n",
    "    max_norm = norms.max()\n",
    "\n",
    "    # add an extra dimension so that the norm of each row is the same\n",
    "    # (max_norm)\n",
    "    extra_dimension = numpy.sqrt(max_norm ** 2 - norms ** 2)\n",
    "    return max_norm, numpy.append(factors, extra_dimension.reshape(norms.shape[0], 1), axis=1)\n",
    "\n",
    "\n",
    "class AnnoyTransformer(TransformerMixin, BaseEstimator):\n",
    "    \"\"\"Wrapper for using annoy.AnnoyIndex as sklearn's KNeighborsTransformer\"\"\"\n",
    "\n",
    "    def __init__(self, n_neighbors=5, metric='euclidean', n_trees=10,\n",
    "                 search_k=-1,approximate_similar_items=True,approximate_recommend=True,\n",
    "                 user_embeddings= None,item_embeddings=None):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.n_trees = n_trees\n",
    "        self.search_k = search_k\n",
    "        self.metric = metric\n",
    "        self.approximate_similar_items = approximate_similar_items\n",
    "        self.approximate_recommend=approximate_recommend\n",
    "        self.user_embeddings = user_embeddings\n",
    "        self.item_embeddings = item_embeddings\n",
    "    def fit(self, X):\n",
    "        self.n_samples_fit_ = X.shape[0]\n",
    "        metric = self.metric if self.metric != 'sqeuclidean' else 'euclidean'\n",
    "        self.annoy_ = annoy.AnnoyIndex(X.shape[1], metric=metric)\n",
    "        for i, x in enumerate(X):\n",
    "            self.annoy_.add_item(i, x.tolist())\n",
    "        self.annoy_.build(self.n_trees)\n",
    "        \n",
    "        #New add\n",
    "        self.item_factors = X\n",
    "        if self.approximate_similar_items:\n",
    "            \n",
    "            log.debug(\"Building annoy similar items index\")\n",
    "            self.similar_items_index = annoy.AnnoyIndex(\n",
    "                self.item_factors.shape[1], 'angular')\n",
    "            for i, row in enumerate(self.item_factors):\n",
    "                self.similar_items_index.add_item(i, row)\n",
    "            self.similar_items_index.build(self.n_trees)\n",
    "            \n",
    "        # build up a separate index for the inner product (for recommend\n",
    "        # methods)\n",
    "        if self.approximate_recommend:\n",
    "            log.debug(\"Building annoy recommendation index\")\n",
    "            self.max_norm, extra = augment_inner_product_matrix(self.item_factors)\n",
    "            self.recommend_index = annoy.AnnoyIndex(extra.shape[1], 'angular')\n",
    "            for i, row in enumerate(extra):\n",
    "                self.recommend_index.add_item(i, row)\n",
    "            self.recommend_index.build(self.n_trees)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self._transform(X)\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X)._transform(X=None)\n",
    "\n",
    "    def _transform(self, X):\n",
    "        \"\"\"As `transform`, but handles X is None for faster `fit_transform`.\"\"\"\n",
    "\n",
    "        n_samples_transform = self.n_samples_fit_ if X is None else X.shape[0]\n",
    "\n",
    "        # For compatibility reasons, as each sample is considered as its own\n",
    "        # neighbor, one extra neighbor will be computed.\n",
    "        n_neighbors = self.n_neighbors + 1\n",
    "\n",
    "        indices = np.empty((n_samples_transform, n_neighbors),\n",
    "                           dtype=np.int)\n",
    "        distances = np.empty((n_samples_transform, n_neighbors))\n",
    "\n",
    "        if X is None:\n",
    "            for i in range(self.annoy_.get_n_items()):\n",
    "                ind, dist = self.annoy_.get_nns_by_item(\n",
    "                    i, n_neighbors, self.search_k, include_distances=True)\n",
    "\n",
    "                indices[i], distances[i] = ind, dist\n",
    "        else:\n",
    "            for i, x in enumerate(X):\n",
    "                indices[i], distances[i] = self.annoy_.get_nns_by_vector(\n",
    "                    x.tolist(), n_neighbors, self.search_k,\n",
    "                    include_distances=True)\n",
    "\n",
    "        if self.metric == 'sqeuclidean':\n",
    "            distances **= 2\n",
    "\n",
    "        indptr = np.arange(0, n_samples_transform * n_neighbors + 1,\n",
    "                           n_neighbors)\n",
    "        kneighbors_graph = csr_matrix((distances.ravel(), indices.ravel(),\n",
    "                                       indptr), shape=(n_samples_transform,\n",
    "                                                       self.n_samples_fit_))\n",
    "\n",
    "        return kneighbors_graph\n",
    "\n",
    "    def similar_items(self, itemid, N=10):\n",
    "        #if not self.approximate_similar_items:\n",
    "        #    return super(AnnoyAlternatingLeastSquares, self).similar_items(itemid, N)\n",
    "\n",
    "        neighbours, dist = self.similar_items_index.get_nns_by_item(itemid, N,\n",
    "                                                                    search_k=self.search_k,\n",
    "                                                                    include_distances=True)\n",
    "        # transform distances back to cosine from euclidean distance\n",
    "        return zip(neighbours, 1 - (numpy.array(dist) ** 2) / 2)\n",
    "\n",
    "    def recommend(self, userid, user_items, N=10, filter_already_liked_items=True,\n",
    "                  filter_items=None, recalculate_user=False):\n",
    "        #if not self.approximate_recommend:\n",
    "        #    return super(NMSLibAlternatingLeastSquares,\n",
    "        #                 self).recommend(userid, user_items, N=N,\n",
    "        #                                filter_items=filter_items,\n",
    "        #                                 recalculate_user=recalculate_user)\n",
    "\n",
    "        #user = self._user_factor(userid, user_items, recalculate_user)\n",
    "\n",
    "        # calculate the top N items, removing the users own liked items from\n",
    "        # the results\n",
    "        liked = set()\n",
    "        #user_items =interactions_matrix \n",
    "        \n",
    "        if filter_already_liked_items:\n",
    "            #liked.update(user_items[userid].indices)\n",
    "            liked.update(user_items.tocsr()[userid].indices)\n",
    "        if filter_items:\n",
    "            liked.update(filter_items)\n",
    "        count = N + len(liked)\n",
    "        \n",
    "        user = self.user_embeddings[userid]\n",
    "        query = numpy.append(user, 0)\n",
    "        ids, dist = self.recommend_index.get_nns_by_vector(query, count, include_distances=True,\n",
    "                                                           search_k=self.search_k)\n",
    "\n",
    "        # convert the distances from euclidean to cosine distance,\n",
    "        # and then rescale the cosine distance to go back to inner product\n",
    "        scaling = self.max_norm * numpy.linalg.norm(query)\n",
    "        dist = scaling * (1 - (numpy.array(dist) ** 2) / 2)\n",
    "        return list(itertools.islice((rec for rec in zip(ids, dist) if rec[0] not in liked), N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norms = np.linalg.norm(item_embeddings, axis=1)\n",
    "max_norm = norms.max()\n",
    "extra_dimension = np.sqrt(max_norm ** 2 - norms ** 2)\n",
    "norm_data = np.append(item_embeddings, extra_dimension.reshape(norms.shape[0], 1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leepand/miniconda3/lib/python3.7/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn('LightFM was compiled without OpenMP support. '\n"
     ]
    }
   ],
   "source": [
    "from lightfm.datasets import fetch_movielens\n",
    "\n",
    "movielens = fetch_movielens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = movielens['train']\n",
    "test = movielens['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: train 0.73, test 0.09.\n",
      "AUC: train 0.97, test 0.91.\n"
     ]
    }
   ],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from lightfm.evaluation import auc_score\n",
    "\n",
    "model = LightFM(learning_rate=0.05, loss='warp', no_components=64, item_alpha=0.001)\n",
    "\n",
    "model.fit_partial(train, item_features=movielens['item_features'], epochs=20 )\n",
    "\n",
    "train_precision = precision_at_k(model, train, k=10).mean()\n",
    "test_precision = precision_at_k(model, test, k=10).mean()\n",
    "\n",
    "train_auc = auc_score(model, train).mean()\n",
    "test_auc = auc_score(model, test).mean()\n",
    "\n",
    "print('Precision: train %.2f, test %.2f.' % (train_precision, test_precision))\n",
    "print('AUC: train %.2f, test %.2f.' % (train_auc, test_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, item_embeddings = model.get_item_representations(movielens['item_features'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our user vectors\n",
    "\n",
    "_, user_embeddings = model.get_user_representations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_recom = AnnoyTransformer(user_embeddings=user_embeddings,item_embeddings=item_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_recom_fit= ann_recom.fit(item_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(136, 2.3265348067071696),\n",
       " (8, 2.1597858030083117),\n",
       " (327, 2.1514774636771485),\n",
       " (123, 2.0236341978902663),\n",
       " (689, 1.9506655407820166),\n",
       " (332, 1.8867702788260263),\n",
       " (311, 1.8791406596704099),\n",
       " (878, 1.838610719839612),\n",
       " (749, 1.836402241329505),\n",
       " (814, 1.8158444006150678),\n",
       " (244, 1.809224028242631),\n",
       " (247, 1.7970648869910224),\n",
       " (507, 1.771336694819363),\n",
       " (321, 1.7449642427173029),\n",
       " (470, 1.7429613719346697),\n",
       " (320, 1.706161021723867),\n",
       " (747, 1.7043134040777057),\n",
       " (14, 1.6970882932241744),\n",
       " (245, 1.68820445688647),\n",
       " (844, 1.6259218379671931)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userid = 1\n",
    "user_items=train\n",
    "ann_recom_fit.recommend(userid, user_items, N=20, filter_already_liked_items=True,\n",
    "                        filter_items=None, recalculate_user=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<943x1682 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 90570 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "956 µs ± 11.7 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "ann_recom_fit.recommend(userid, user_items, N=10, filter_already_liked_items=True,\n",
    "                        filter_items=None, recalculate_user=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 0.9999998892660652)\n",
      "(115, 0.6977784538841831)\n",
      "(18, 0.6950377336570952)\n",
      "(13, 0.6064464370531084)\n",
      "(9, 0.582929925711694)\n",
      "(15, 0.5719863354176322)\n",
      "(693, 0.5397662146593358)\n",
      "(220, 0.5388534283593724)\n",
      "(56, 0.5366351592978997)\n",
      "(935, 0.5288477023333868)\n"
     ]
    }
   ],
   "source": [
    "for i in ann_recom_fit.similar_items(19):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting model annoy_als\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "__main__.AnnoyTransformer"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# maps command line model argument to class name\n",
    "MODELS = {\"annoy_als\": AnnoyTransformer,\n",
    "          \"lmf\":LFMRecommender}\n",
    "\n",
    "\n",
    "def get_model(model_name):\n",
    "    print(\"getting model %s\" % model_name)\n",
    "    model_class = MODELS.get(model_name)\n",
    "    if not model_class:\n",
    "        raise ValueError(\"Unknown Model '%s'\" % model_name)\n",
    "\n",
    "    # some default params\n",
    "    if issubclass(model_class, TransformerMixin):\n",
    "        params = {}\n",
    "    elif model_name == \"bm25\":\n",
    "        params = {'K1': 100, 'B': 0.5}\n",
    "    elif model_name == \"bpr\":\n",
    "        params = {'factors': 63}\n",
    "    elif model_name == \"lmf\":\n",
    "        params = {'factors': 30, \"iterations\": 40, \"regularization\": 1.5}\n",
    "    else:\n",
    "        params = {}\n",
    "\n",
    "    return model_class#(**params)\n",
    "\n",
    "get_model(\"annoy_als\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
